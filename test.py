import cv2
from cvzone.HandTrackingModule import HandDetector
from cvzone.ClassificationModule import Classifier
import numpy as np
import math

#Sensing env using camera
cap = cv2.VideoCapture(0)

#Finding hand out of entire frame
detector = HandDetector(maxHands=1)

#take input from camera and put it in a class

classifier = Classifier("model/keras_model.h5", "model/labels.txt")

spacing  =30
imgSize = 400
folderPath = "data/C"
count = 0
labels = ["Perfect", "Excuse","Goodluck", "Thanks", "Thanks", "Less", "More","No", "Yes", "Hello"]




print("\n\033[4mThe text generated by hand gestures :\033[0m\n")
print("Follow the directions to translate the hand signs:")
print("\t1 - Once the camera is active, perform hand signs within the camera's view.")
print("\t2 - The predicted meaning of hand sign will be displayed on camera display.")
print("\t3 - Press SPACE to close the camera and exit the application.")
while True:
    inp = input("Press ENTER to launch camera!")
    if(inp==""):
    # capturing the hand via camera
        while True:
            
            success, img = cap.read()
            imgOutput = img.copy()
            hands, img = detector.findHands(img)
            if hands:
                hand=hands[0]
                x,y,w,h = hand['bbox']
                
                imgBackground = np.ones((imgSize, imgSize, 3), np.uint8)*255 #<---- Since the image is colored and range of colors is 0-255 i.e. 8 bit numbers
                cropImg = img[y-spacing:y+h+spacing, x-spacing:x+w+spacing]
                
                cropImgShape = cropImg.shape
                
                ratio = h/w
                if ratio>1:
                    const = imgSize/h
                    wNew = math.ceil(const*w)
                    resizeImage = cv2.resize(cropImg, (wNew, imgSize))
                    resizeImgShape = resizeImage.shape
                    centerGap = math.ceil((imgSize-wNew)/2)
                    imgBackground[0:resizeImgShape[0], centerGap:wNew+centerGap] = resizeImage
                    prediction, index = classifier.getPrediction(imgBackground)
                    print(prediction, index)
                    
                    
                else:
                    const = imgSize/w
                    hNew = math.ceil(const*h)
                    resizeImage = cv2.resize(cropImg, (imgSize, hNew))
                    resizeImgShape = resizeImage.shape
                    centerGap = math.ceil((imgSize-hNew)/2)
                    imgBackground[centerGap:hNew+centerGap, : ] = resizeImage
                    prediction, index = classifier.getPrediction(imgBackground)
                    print(prediction, index)
                    
                cv2.putText(imgOutput, labels[index], (x-5, y -30), cv2.FONT_HERSHEY_SIMPLEX, 3, (0, 0, 0),7)
                cv2.rectangle(imgOutput, (x-spacing, y-spacing),(x + w+spacing, y + h+spacing), (0, 0, 0), 7)
                
                
            cv2.imshow("Image", imgOutput)
            key = cv2.waitKey(1)
                
            if key== ord("q"):
                print("Exiting the application.")
                break

        
    else:
        print("Enter a valid command!")